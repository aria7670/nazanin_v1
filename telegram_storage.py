"""
Telegram Storage System
Ø³ÛŒØ³ØªÙ… Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ùˆ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¯Ø± ØªÙ„Ú¯Ø±Ø§Ù…
"""

import asyncio
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime
import json
import pickle
import base64
from telethon import TelegramClient
from telethon.tl.types import InputMessagesFilterDocument

logger = logging.getLogger(__name__)


class TelegramStorage:
    """Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø± ØªÙ„Ú¯Ø±Ø§Ù…"""
    
    def __init__(self, client: TelegramClient, storage_channel_id: str):
        self.client = client
        self.storage_channel_id = storage_channel_id
        self.index = {}  # ÙÙ‡Ø±Ø³Øª ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡
        self.initialized = False
        
    async def initialize(self):
        """Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡"""
        try:
            # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ index Ø§Ø² Ú©Ø§Ù†Ø§Ù„
            await self._load_index()
            self.initialized = True
            logger.info("âœ… Telegram storage initialized")
        except Exception as e:
            logger.error(f"âŒ Failed to initialize Telegram storage: {e}")
            raise
    
    async def store_data(self, key: str, data: Any, 
                        metadata: Optional[Dict] = None) -> str:
        """Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡"""
        try:
            # ØªØ¨Ø¯ÛŒÙ„ Ø¯Ø§Ø¯Ù‡ Ø¨Ù‡ JSON
            if isinstance(data, (dict, list)):
                content = json.dumps(data, ensure_ascii=False, indent=2)
                file_type = 'json'
            elif isinstance(data, str):
                content = data
                file_type = 'text'
            else:
                # Ø³Ø±ÛŒØ§Ù„ÛŒØ² Ú©Ø±Ø¯Ù† Ø§Ø´ÛŒØ§Ø¡ Ù¾ÛŒÚ†ÛŒØ¯Ù‡
                content = base64.b64encode(pickle.dumps(data)).decode()
                file_type = 'binary'
            
            # Ø³Ø§Ø®Øª Ù¾ÛŒØ§Ù…
            timestamp = datetime.now().isoformat()
            message = f"""ğŸ“¦ **Storage Entry**

ğŸ”‘ Key: `{key}`
ğŸ“… Timestamp: {timestamp}
ğŸ“ Type: {file_type}
ğŸ“Š Size: {len(content)} bytes

{metadata if metadata else ''}

{'='*50}

{content if len(content) < 3000 else content[:3000] + '...[truncated]'}
"""
            
            # Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ Ú©Ø§Ù†Ø§Ù„
            sent_message = await self.client.send_message(
                self.storage_channel_id,
                message
            )
            
            # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ index
            self.index[key] = {
                'message_id': sent_message.id,
                'timestamp': timestamp,
                'type': file_type,
                'size': len(content),
                'metadata': metadata
            }
            
            # Ø°Ø®ÛŒØ±Ù‡ index
            await self._save_index()
            
            logger.info(f"âœ… Stored data with key: {key}")
            
            return f"telegram://message/{sent_message.id}"
            
        except Exception as e:
            logger.error(f"âŒ Failed to store data: {e}")
            raise
    
    async def store_file(self, key: str, file_path: str, 
                        metadata: Optional[Dict] = None) -> str:
        """Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„"""
        try:
            # Ø¢Ù¾Ù„ÙˆØ¯ ÙØ§ÛŒÙ„
            sent_file = await self.client.send_file(
                self.storage_channel_id,
                file_path,
                caption=f"ğŸ“ File: {key}\nâ° {datetime.now().isoformat()}\n\n{json.dumps(metadata, ensure_ascii=False) if metadata else ''}"
            )
            
            # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ index
            self.index[key] = {
                'message_id': sent_file.id,
                'timestamp': datetime.now().isoformat(),
                'type': 'file',
                'file_path': file_path,
                'metadata': metadata
            }
            
            await self._save_index()
            
            logger.info(f"âœ… Stored file: {key}")
            
            return f"telegram://file/{sent_file.id}"
            
        except Exception as e:
            logger.error(f"âŒ Failed to store file: {e}")
            raise
    
    async def retrieve_data(self, key: str) -> Optional[Any]:
        """Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø¯Ø§Ø¯Ù‡"""
        try:
            if key not in self.index:
                logger.warning(f"âš ï¸ Key not found: {key}")
                return None
            
            entry = self.index[key]
            message_id = entry['message_id']
            file_type = entry['type']
            
            # Ø¯Ø±ÛŒØ§ÙØª Ù¾ÛŒØ§Ù…
            message = await self.client.get_messages(
                self.storage_channel_id,
                ids=message_id
            )
            
            if not message:
                return None
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø­ØªÙˆØ§
            content = message.text
            
            # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹
            if file_type == 'json':
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ JSON Ø§Ø² Ù¾ÛŒØ§Ù…
                json_start = content.find('{')
                if json_start == -1:
                    json_start = content.find('[')
                
                if json_start != -1:
                    json_content = content[json_start:]
                    return json.loads(json_content)
            
            elif file_type == 'text':
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ†
                separator = '=' * 50
                if separator in content:
                    parts = content.split(separator)
                    return parts[-1].strip()
                return content
            
            elif file_type == 'binary':
                # Ø¯ÛŒâ€ŒØ³Ø±ÛŒØ§Ù„ÛŒØ²
                separator = '=' * 50
                if separator in content:
                    parts = content.split(separator)
                    encoded = parts[-1].strip()
                    return pickle.loads(base64.b64decode(encoded))
            
            return content
            
        except Exception as e:
            logger.error(f"âŒ Failed to retrieve data: {e}")
            return None
    
    async def retrieve_file(self, key: str, download_path: str) -> Optional[str]:
        """Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ ÙØ§ÛŒÙ„"""
        try:
            if key not in self.index:
                return None
            
            entry = self.index[key]
            message_id = entry['message_id']
            
            # Ø¯Ø±ÛŒØ§ÙØª Ù¾ÛŒØ§Ù…
            message = await self.client.get_messages(
                self.storage_channel_id,
                ids=message_id
            )
            
            if not message or not message.media:
                return None
            
            # Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„
            downloaded_path = await self.client.download_media(
                message,
                file=download_path
            )
            
            logger.info(f"âœ… Retrieved file: {key}")
            
            return downloaded_path
            
        except Exception as e:
            logger.error(f"âŒ Failed to retrieve file: {e}")
            return None
    
    async def list_keys(self, filter_type: Optional[str] = None) -> List[str]:
        """Ù„ÛŒØ³Øª Ú©Ù„ÛŒØ¯Ù‡Ø§"""
        if filter_type:
            return [
                key for key, entry in self.index.items()
                if entry.get('type') == filter_type
            ]
        return list(self.index.keys())
    
    async def delete_data(self, key: str) -> bool:
        """Ø­Ø°Ù Ø¯Ø§Ø¯Ù‡"""
        try:
            if key not in self.index:
                return False
            
            entry = self.index[key]
            message_id = entry['message_id']
            
            # Ø­Ø°Ù Ù¾ÛŒØ§Ù…
            await self.client.delete_messages(
                self.storage_channel_id,
                [message_id]
            )
            
            # Ø­Ø°Ù Ø§Ø² index
            del self.index[key]
            await self._save_index()
            
            logger.info(f"âœ… Deleted data: {key}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ Failed to delete data: {e}")
            return False
    
    async def search(self, query: str) -> List[Dict]:
        """Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§"""
        results = []
        
        for key, entry in self.index.items():
            if query.lower() in key.lower():
                results.append({
                    'key': key,
                    'entry': entry
                })
            elif entry.get('metadata') and query.lower() in str(entry['metadata']).lower():
                results.append({
                    'key': key,
                    'entry': entry
                })
        
        return results
    
    async def _save_index(self):
        """Ø°Ø®ÛŒØ±Ù‡ index"""
        try:
            index_json = json.dumps(self.index, ensure_ascii=False, indent=2)
            
            # Ø¬Ø³ØªØ¬ÙˆÛŒ Ù¾ÛŒØ§Ù… index Ù‚Ø¨Ù„ÛŒ
            messages = await self.client.get_messages(
                self.storage_channel_id,
                search='ğŸ“š Storage Index'
            )
            
            if messages:
                # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ
                await self.client.edit_message(
                    self.storage_channel_id,
                    messages[0].id,
                    f"ğŸ“š **Storage Index**\n\nLast Updated: {datetime.now().isoformat()}\n\nTotal Entries: {len(self.index)}\n\n```json\n{index_json}\n```"
                )
            else:
                # Ø§ÛŒØ¬Ø§Ø¯ Ø¬Ø¯ÛŒØ¯
                await self.client.send_message(
                    self.storage_channel_id,
                    f"ğŸ“š **Storage Index**\n\nCreated: {datetime.now().isoformat()}\n\nTotal Entries: {len(self.index)}\n\n```json\n{index_json}\n```"
                )
            
        except Exception as e:
            logger.error(f"âŒ Failed to save index: {e}")
    
    async def _load_index(self):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ index"""
        try:
            messages = await self.client.get_messages(
                self.storage_channel_id,
                search='ğŸ“š Storage Index'
            )
            
            if messages and messages[0].text:
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ JSON
                text = messages[0].text
                json_start = text.find('```json') + 7
                json_end = text.find('```', json_start)
                
                if json_start > 6 and json_end > json_start:
                    index_json = text[json_start:json_end].strip()
                    self.index = json.loads(index_json)
                    logger.info(f"âœ… Loaded index with {len(self.index)} entries")
            else:
                logger.info("â„¹ï¸ No existing index found, starting fresh")
                self.index = {}
                
        except Exception as e:
            logger.error(f"âŒ Failed to load index: {e}")
            self.index = {}
    
    async def get_stats(self) -> Dict[str, Any]:
        """Ø¢Ù…Ø§Ø± Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ"""
        type_distribution = {}
        total_size = 0
        
        for entry in self.index.values():
            entry_type = entry.get('type', 'unknown')
            type_distribution[entry_type] = type_distribution.get(entry_type, 0) + 1
            total_size += entry.get('size', 0)
        
        return {
            'total_entries': len(self.index),
            'type_distribution': type_distribution,
            'total_size_bytes': total_size,
            'total_size_mb': total_size / (1024 * 1024),
            'storage_channel': self.storage_channel_id
        }


class DataBackupSystem:
    """Ø³ÛŒØ³ØªÙ… Ù¾Ø´ØªÛŒØ¨Ø§Ù†â€ŒÚ¯ÛŒØ±ÛŒ"""
    
    def __init__(self, telegram_storage: TelegramStorage):
        self.storage = telegram_storage
        self.backup_history = []
        
    async def backup_data(self, data_name: str, data: Any, 
                         backup_type: str = 'incremental') -> str:
        """Ù¾Ø´ØªÛŒØ¨Ø§Ù†â€ŒÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø¯Ø§Ø¯Ù‡"""
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_key = f"backup_{data_name}_{timestamp}"
        
        metadata = {
            'backup_type': backup_type,
            'original_name': data_name,
            'timestamp': timestamp,
            'data_type': type(data).__name__
        }
        
        # Ø°Ø®ÛŒØ±Ù‡
        storage_ref = await self.storage.store_data(
            backup_key,
            data,
            metadata
        )
        
        # Ø«Ø¨Øª Ø¯Ø± ØªØ§Ø±ÛŒØ®Ú†Ù‡
        self.backup_history.append({
            'key': backup_key,
            'ref': storage_ref,
            'metadata': metadata
        })
        
        logger.info(f"âœ… Backup created: {backup_key}")
        
        return backup_key
    
    async def restore_backup(self, backup_key: str) -> Optional[Any]:
        """Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø§Ø² Ù¾Ø´ØªÛŒØ¨Ø§Ù†"""
        
        data = await self.storage.retrieve_data(backup_key)
        
        if data:
            logger.info(f"âœ… Backup restored: {backup_key}")
        
        return data
    
    async def list_backups(self, data_name: Optional[str] = None) -> List[Dict]:
        """Ù„ÛŒØ³Øª Ù¾Ø´ØªÛŒØ¨Ø§Ù†â€ŒÙ‡Ø§"""
        
        if data_name:
            return [
                backup for backup in self.backup_history
                if backup['metadata']['original_name'] == data_name
            ]
        
        return self.backup_history
    
    async def auto_backup(self, data_dict: Dict[str, Any]):
        """Ù¾Ø´ØªÛŒØ¨Ø§Ù†â€ŒÚ¯ÛŒØ±ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± Ø§Ø² Ú†Ù†Ø¯ÛŒÙ† Ø¯Ø§Ø¯Ù‡"""
        
        logger.info("ğŸ”„ Starting auto-backup...")
        
        backup_refs = {}
        
        for name, data in data_dict.items():
            try:
                ref = await self.backup_data(name, data, 'auto')
                backup_refs[name] = ref
            except Exception as e:
                logger.error(f"âŒ Failed to backup {name}: {e}")
        
        logger.info(f"âœ… Auto-backup completed: {len(backup_refs)} items backed up")
        
        return backup_refs


class CacheSystem:
    """Ø³ÛŒØ³ØªÙ… Ú©Ø´ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù† Ø¯Ø± ØªÙ„Ú¯Ø±Ø§Ù…"""
    
    def __init__(self, telegram_storage: TelegramStorage, 
                 cache_duration_seconds: int = 3600):
        self.storage = telegram_storage
        self.cache_duration = cache_duration_seconds
        self.memory_cache = {}
        self.cache_metadata = {}
        
    async def get(self, key: str, fetch_function=None) -> Optional[Any]:
        """Ø¯Ø±ÛŒØ§ÙØª Ø§Ø² Ú©Ø´"""
        
        # Ø¨Ø±Ø±Ø³ÛŒ memory cache
        if key in self.memory_cache:
            metadata = self.cache_metadata.get(key, {})
            cached_time = metadata.get('cached_at')
            
            if cached_time:
                age = (datetime.now() - datetime.fromisoformat(cached_time)).total_seconds()
                
                if age < self.cache_duration:
                    logger.debug(f"ğŸ’¨ Cache hit (memory): {key}")
                    return self.memory_cache[key]
        
        # Ø¨Ø±Ø±Ø³ÛŒ Telegram storage
        data = await self.storage.retrieve_data(f"cache_{key}")
        
        if data:
            # Ø¨Ø±Ø±Ø³ÛŒ ØªØ§Ø±ÛŒØ® Ø§Ù†Ù‚Ø¶Ø§
            metadata = self.cache_metadata.get(key, {})
            cached_time = metadata.get('cached_at')
            
            if cached_time:
                age = (datetime.now() - datetime.fromisoformat(cached_time)).total_seconds()
                
                if age < self.cache_duration:
                    # Ø¨Ø§Ø²Ú¯Ø±Ø¯Ø§Ù†ÛŒ Ø¨Ù‡ memory
                    self.memory_cache[key] = data
                    logger.debug(f"ğŸ’¨ Cache hit (telegram): {key}")
                    return data
        
        # Cache miss - fetch Ø¬Ø¯ÛŒØ¯
        if fetch_function:
            logger.debug(f"ğŸ”„ Cache miss, fetching: {key}")
            data = await fetch_function()
            await self.set(key, data)
            return data
        
        return None
    
    async def set(self, key: str, value: Any):
        """Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ú©Ø´"""
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± memory
        self.memory_cache[key] = value
        
        # Ø°Ø®ÛŒØ±Ù‡ metadata
        self.cache_metadata[key] = {
            'cached_at': datetime.now().isoformat(),
            'size': len(str(value))
        }
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Telegram
        await self.storage.store_data(
            f"cache_{key}",
            value,
            self.cache_metadata[key]
        )
        
        logger.debug(f"âœ… Cached: {key}")
    
    async def invalidate(self, key: str):
        """Ø¨Ø§Ø·Ù„ Ú©Ø±Ø¯Ù† Ú©Ø´"""
        
        if key in self.memory_cache:
            del self.memory_cache[key]
        
        if key in self.cache_metadata:
            del self.cache_metadata[key]
        
        await self.storage.delete_data(f"cache_{key}")
        
        logger.debug(f"ğŸ—‘ï¸ Cache invalidated: {key}")
    
    async def clear_all(self):
        """Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† ØªÙ…Ø§Ù… Ú©Ø´"""
        
        self.memory_cache.clear()
        self.cache_metadata.clear()
        
        # Ø­Ø°Ù Ø§Ø² Telegram
        cache_keys = await self.storage.list_keys()
        cache_keys = [k for k in cache_keys if k.startswith('cache_')]
        
        for key in cache_keys:
            await self.storage.delete_data(key)
        
        logger.info("ğŸ—‘ï¸ All cache cleared")
