"""
10 Specialized Agents for Different Tasks
10 Ø§ÛŒØ¬Ù†Øª ØªØ®ØµØµÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ù†Ø¬Ø§Ù… ØªØ³Ú©â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù - Ú©Ø§Ù…Ù„Ø§Ù‹ Ù…Ø§Ú˜ÙˆÙ„Ø§Ø±
"""

import asyncio
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
from abc import ABC, abstractmethod
import json
import re

logger = logging.getLogger(__name__)


class BaseSpecializedAgent(ABC):
    """Ú©Ù„Ø§Ø³ Ù¾Ø§ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ ØªÙ…Ø§Ù… Ø§ÛŒØ¬Ù†Øªâ€ŒÙ‡Ø§ÛŒ ØªØ®ØµØµÛŒ"""
    
    def __init__(self, name: str, api_manager, sheets_manager):
        self.name = name
        self.api_manager = api_manager
        self.sheets_manager = sheets_manager
        self.task_history = []
        self.performance_metrics = {
            'total_tasks': 0,
            'successful_tasks': 0,
            'failed_tasks': 0,
            'average_response_time': 0.0
        }
        logger.info(f"âœ… {name} agent initialized")
    
    @abstractmethod
    async def execute(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """Ø§Ø¬Ø±Ø§ÛŒ ØªØ³Ú© - Ø¨Ø§ÛŒØ¯ ØªÙˆØ³Ø· Ù‡Ø± Ø§ÛŒØ¬Ù†Øª Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´ÙˆØ¯"""
        pass
    
    async def _record_task(self, task: Dict, result: Dict, success: bool):
        """Ø«Ø¨Øª ØªØ³Ú©"""
        self.task_history.append({
            'task': task,
            'result': result,
            'success': success,
            'timestamp': datetime.now().isoformat()
        })
        
        self.performance_metrics['total_tasks'] += 1
        if success:
            self.performance_metrics['successful_tasks'] += 1
        else:
            self.performance_metrics['failed_tasks'] += 1
    
    def get_performance(self) -> Dict[str, Any]:
        """Ø¯Ø±ÛŒØ§ÙØª Ø¹Ù…Ù„Ú©Ø±Ø¯"""
        total = self.performance_metrics['total_tasks']
        if total == 0:
            success_rate = 0
        else:
            success_rate = self.performance_metrics['successful_tasks'] / total
        
        return {
            'agent': self.name,
            'metrics': self.performance_metrics,
            'success_rate': success_rate,
            'recent_tasks': self.task_history[-10:]
        }


class ContentOptimizationAgent(BaseSpecializedAgent):
    """Ø§ÛŒØ¬Ù†Øª 1: Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø­ØªÙˆØ§ Ù‚Ø¨Ù„ Ø§Ø² Ø§Ù†ØªØ´Ø§Ø±"""
    
    def __init__(self, api_manager, sheets_manager):
        super().__init__("ContentOptimization", api_manager, sheets_manager)
        self.optimization_rules = self._load_rules()
    
    def _load_rules(self) -> List[Dict]:
        """Ù‚ÙˆØ§Ù†ÛŒÙ† Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ"""
        return [
            {
                'name': 'length_check',
                'condition': lambda text: len(text) > 280,
                'action': 'shorten',
                'priority': 10
            },
            {
                'name': 'hashtag_optimization',
                'condition': lambda text: text.count('#') > 3,
                'action': 'reduce_hashtags',
                'priority': 8
            },
            {
                'name': 'emoji_balance',
                'condition': lambda text: len(re.findall(r'[\U0001F600-\U0001F64F]', text)) > 5,
                'action': 'reduce_emojis',
                'priority': 6
            },
            {
                'name': 'url_shortening',
                'condition': lambda text: 'http' in text,
                'action': 'shorten_urls',
                'priority': 7
            }
        ]
    
    async def execute(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø­ØªÙˆØ§"""
        try:
            content = task.get('content', '')
            platform = task.get('platform', 'twitter')
            
            optimized = content
            applied_rules = []
            
            # Ø§Ø¹Ù…Ø§Ù„ Ù‚ÙˆØ§Ù†ÛŒÙ†
            for rule in sorted(self.optimization_rules, key=lambda x: x['priority'], reverse=True):
                if rule['condition'](optimized):
                    optimized = await self._apply_rule(optimized, rule['action'], platform)
                    applied_rules.append(rule['name'])
            
            # ØªØ­Ù„ÛŒÙ„ Ú©ÛŒÙÛŒØª
            quality_score = await self._analyze_quality(optimized, platform)
            
            result = {
                'original': content,
                'optimized': optimized,
                'applied_rules': applied_rules,
                'quality_score': quality_score,
                'improvements': self._list_improvements(content, optimized)
            }
            
            await self._record_task(task, result, True)
            return result
            
        except Exception as e:
            logger.error(f"âŒ ContentOptimization error: {e}")
            await self._record_task(task, {'error': str(e)}, False)
            return {'error': str(e)}
    
    async def _apply_rule(self, content: str, action: str, platform: str) -> str:
        """Ø§Ø¹Ù…Ø§Ù„ ÛŒÚ© Ù‚Ø§Ù†ÙˆÙ†"""
        if action == 'shorten':
            return content[:270] + "..." if len(content) > 280 else content
        elif action == 'reduce_hashtags':
            hashtags = re.findall(r'#\w+', content)
            if len(hashtags) > 3:
                for hashtag in hashtags[3:]:
                    content = content.replace(hashtag, '', 1)
            return content
        elif action == 'reduce_emojis':
            # Ø­Ø°Ù emojiâ€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ
            return content  # Ø³Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡
        elif action == 'shorten_urls':
            # Ø¯Ø± ÙˆØ§Ù‚Ø¹ÛŒØªØŒ Ø§Ø² URL shortener Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
            return content
        return content
    
    async def _analyze_quality(self, content: str, platform: str) -> float:
        """ØªØ­Ù„ÛŒÙ„ Ú©ÛŒÙÛŒØª Ù…Ø­ØªÙˆØ§"""
        score = 5.0  # Ø§Ø² 10
        
        # Ø·ÙˆÙ„ Ù…Ù†Ø§Ø³Ø¨
        if 50 < len(content) < 250:
            score += 2
        
        # ØªØ¹Ø¯Ø§Ø¯ hashtag Ù…Ù†Ø§Ø³Ø¨
        hashtag_count = content.count('#')
        if 1 <= hashtag_count <= 3:
            score += 1
        
        # Ø¯Ø§Ø±Ø§ÛŒ call-to-action
        cta_words = ['check', 'read', 'watch', 'learn', 'Ø¨Ø¨ÛŒÙ†', 'Ø¨Ø®ÙˆÙ†']
        if any(word in content.lower() for word in cta_words):
            score += 1
        
        # Ø®ÙˆØ§Ù†Ø§ÛŒÛŒ
        sentences = content.split('.')
        if 2 <= len(sentences) <= 4:
            score += 1
        
        return min(score, 10.0)
    
    def _list_improvements(self, original: str, optimized: str) -> List[str]:
        """Ù„ÛŒØ³Øª Ø¨Ù‡Ø¨ÙˆØ¯Ù‡Ø§"""
        improvements = []
        
        if len(optimized) < len(original):
            improvements.append("Length reduced for better engagement")
        
        if original.count('#') > optimized.count('#'):
            improvements.append("Hashtags optimized")
        
        return improvements


class EngagementPredictorAgent(BaseSpecializedAgent):
    """Ø§ÛŒØ¬Ù†Øª 2: Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…ÛŒØ²Ø§Ù† ØªØ¹Ø§Ù…Ù„"""
    
    def __init__(self, api_manager, sheets_manager):
        super().__init__("EngagementPredictor", api_manager, sheets_manager)
        self.historical_data = []
    
    async def execute(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ engagement"""
        try:
            content = task.get('content', '')
            platform = task.get('platform', 'twitter')
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
            features = self._extract_features(content, platform)
            
            # Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
            prediction = await self._predict(features)
            
            # ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§
            recommendations = self._generate_recommendations(features, prediction)
            
            result = {
                'predicted_likes': prediction['likes'],
                'predicted_retweets': prediction['retweets'],
                'predicted_replies': prediction['replies'],
                'engagement_score': prediction['overall_score'],
                'confidence': prediction['confidence'],
                'recommendations': recommendations
            }
            
            await self._record_task(task, result, True)
            return result
            
        except Exception as e:
            logger.error(f"âŒ EngagementPredictor error: {e}")
            await self._record_task(task, {'error': str(e)}, False)
            return {'error': str(e)}
    
    def _extract_features(self, content: str, platform: str) -> Dict[str, Any]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§"""
        return {
            'length': len(content),
            'word_count': len(content.split()),
            'has_emoji': bool(re.search(r'[\U0001F600-\U0001F64F]', content)),
            'has_hashtag': '#' in content,
            'has_url': 'http' in content,
            'has_mention': '@' in content,
            'has_question': '?' in content,
            'sentiment': 'positive' if any(w in content.lower() for w in ['good', 'great', 'awesome']) else 'neutral',
            'hour': datetime.now().hour,
            'day_of_week': datetime.now().weekday()
        }
    
    async def _predict(self, features: Dict) -> Dict[str, Any]:
        """Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ (Ù…Ø¯Ù„ Ø³Ø§Ø¯Ù‡)"""
        base_score = 50
        
        # ØªØ§Ø«ÛŒØ± ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
        if features['has_emoji']:
            base_score += 15
        if features['has_hashtag']:
            base_score += 10
        if features['has_question']:
            base_score += 20
        if 50 < features['length'] < 200:
            base_score += 15
        if features['sentiment'] == 'positive':
            base_score += 10
        
        # Ø²Ù…Ø§Ù† Ø¨Ù‡ÛŒÙ†Ù‡
        if 9 <= features['hour'] <= 17:
            base_score += 10
        
        return {
            'likes': int(base_score * 1.5),
            'retweets': int(base_score * 0.3),
            'replies': int(base_score * 0.2),
            'overall_score': base_score,
            'confidence': 0.7
        }
    
    def _generate_recommendations(self, features: Dict, prediction: Dict) -> List[str]:
        """ØªÙˆÙ„ÛŒØ¯ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§"""
        recs = []
        
        if not features['has_emoji']:
            recs.append("Ø§ÙØ²ÙˆØ¯Ù† emoji Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ engagement Ø±Ø§ 15% Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ù‡Ø¯")
        
        if not features['has_hashtag']:
            recs.append("Ø§ÙØ²ÙˆØ¯Ù† 1-2 hashtag Ù…Ø±ØªØ¨Ø· ØªÙˆØµÛŒÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯")
        
        if features['length'] > 250:
            recs.append("Ù…Ø­ØªÙˆØ§ÛŒ Ú©ÙˆØªØ§Ù‡â€ŒØªØ± Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ Ø¨Ù‡ØªØ± Ø¹Ù…Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯")
        
        if prediction['overall_score'] < 50:
            recs.append("âš ï¸ Ø§ÛŒÙ† Ù…Ø­ØªÙˆØ§ Ù…Ù…Ú©Ù† Ø§Ø³Øª engagement Ù¾Ø§ÛŒÛŒÙ†ÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯")
        
        return recs


class TrendAnalysisAgent(BaseSpecializedAgent):
    """Ø§ÛŒØ¬Ù†Øª 3: ØªØ­Ù„ÛŒÙ„ ØªØ±Ù†Ø¯Ù‡Ø§"""
    
    def __init__(self, api_manager, sheets_manager):
        super().__init__("TrendAnalysis", api_manager, sheets_manager)
        self.trends_cache = {}
    
    async def execute(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """ØªØ­Ù„ÛŒÙ„ ØªØ±Ù†Ø¯Ù‡Ø§"""
        try:
            category = task.get('category', 'AI')
            region = task.get('region', 'global')
            
            # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ ØªØ±Ù†Ø¯Ù‡Ø§
            trends = await self._collect_trends(category, region)
            
            # ØªØ­Ù„ÛŒÙ„
            analysis = await self._analyze_trends(trends)
            
            # Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…Ø­ØªÙˆØ§
            content_suggestions = await self._suggest_content(trends, analysis)
            
            result = {
                'trends': trends[:10],
                'analysis': analysis,
                'content_suggestions': content_suggestions,
                'timestamp': datetime.now().isoformat()
            }
            
            # Ú©Ø´ Ú©Ø±Ø¯Ù†
            self.trends_cache[f"{category}_{region}"] = result
            
            await self._record_task(task, result, True)
            return result
            
        except Exception as e:
            logger.error(f"âŒ TrendAnalysis error: {e}")
            return {'error': str(e)}
    
    async def _collect_trends(self, category: str, region: str) -> List[Dict]:
        """Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ ØªØ±Ù†Ø¯Ù‡Ø§ (Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ)"""
        # Ø¯Ø± ÙˆØ§Ù‚Ø¹ÛŒØªØŒ Ø§Ø² APIâ€ŒÙ‡Ø§ÛŒ Google Trends, Twitter Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
        sample_trends = [
            {'topic': 'GPT-4', 'volume': 95000, 'growth': '+120%'},
            {'topic': 'AI Ethics', 'volume': 45000, 'growth': '+45%'},
            {'topic': 'Quantum Computing', 'volume': 32000, 'growth': '+78%'},
            {'topic': 'Machine Learning', 'volume': 89000, 'growth': '+23%'},
            {'topic': 'Neural Networks', 'volume': 56000, 'growth': '+67%'}
        ]
        
        return sample_trends
    
    async def _analyze_trends(self, trends: List[Dict]) -> Dict:
        """ØªØ­Ù„ÛŒÙ„ ØªØ±Ù†Ø¯Ù‡Ø§"""
        return {
            'hottest_topic': trends[0]['topic'] if trends else None,
            'average_growth': '+65%',
            'emerging_topics': [t['topic'] for t in trends if int(t['growth'].replace('%', '').replace('+', '')) > 50],
            'stability': 'moderate'
        }
    
    async def _suggest_content(self, trends: List[Dict], analysis: Dict) -> List[str]:
        """Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ù…Ø­ØªÙˆØ§ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ±Ù†Ø¯Ù‡Ø§"""
        suggestions = []
        
        for trend in trends[:3]:
            suggestions.append(
                f"Ù¾Ø³Øª Ø¯Ø±Ø¨Ø§Ø±Ù‡ {trend['topic']} (volume: {trend['volume']}, growth: {trend['growth']})"
            )
        
        return suggestions


class SchedulingOptimizerAgent(BaseSpecializedAgent):
    """Ø§ÛŒØ¬Ù†Øª 4: Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ"""
    
    def __init__(self, api_manager, sheets_manager):
        super().__init__("SchedulingOptimizer", api_manager, sheets_manager)
        self.performance_by_time = {}
    
    async def execute(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ"""
        try:
            content_type = task.get('content_type', 'general')
            platform = task.get('platform', 'twitter')
            
            # ØªØ­Ù„ÛŒÙ„ Ø²Ù…Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡
            optimal_times = await self._find_optimal_times(platform, content_type)
            
            # Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒØ±ÛŒØ²ÛŒ Ù‡ÙØªÚ¯ÛŒ
            weekly_schedule = await self._create_weekly_schedule(optimal_times)
            
            result = {
                'optimal_times': optimal_times,
                'weekly_schedule': weekly_schedule,
                'next_recommended_time': optimal_times[0] if optimal_times else None
            }
            
            await self._record_task(task, result, True)
            return result
            
        except Exception as e:
            logger.error(f"âŒ SchedulingOptimizer error: {e}")
            return {'error': str(e)}
    
    async def _find_optimal_times(self, platform: str, content_type: str) -> List[Dict]:
        """ÛŒØ§ÙØªÙ† Ø¨Ù‡ØªØ±ÛŒÙ† Ø²Ù…Ø§Ù†â€ŒÙ‡Ø§"""
        # Ø²Ù…Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡ Ø¹Ù…ÙˆÙ…ÛŒ (Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ­Ù‚ÛŒÙ‚Ø§Øª)
        twitter_optimal = [
            {'hour': 9, 'day': 'weekday', 'score': 85},
            {'hour': 12, 'day': 'weekday', 'score': 90},
            {'hour': 17, 'day': 'weekday', 'score': 95},
            {'hour': 20, 'day': 'any', 'score': 88},
        ]
        
        return twitter_optimal
    
    async def _create_weekly_schedule(self, optimal_times: List[Dict]) -> Dict:
        """Ø³Ø§Ø®Øª Ø¨Ø±Ù†Ø§Ù…Ù‡ Ù‡ÙØªÚ¯ÛŒ"""
        schedule = {}
        days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
        
        for day in days:
            schedule[day] = [
                f"{time['hour']:02d}:00" 
                for time in optimal_times 
                if time['day'] in ['any', 'weekday' if day not in ['Saturday', 'Sunday'] else 'weekend']
            ]
        
        return schedule


class HashtagGeneratorAgent(BaseSpecializedAgent):
    """Ø§ÛŒØ¬Ù†Øª 5: ØªÙˆÙ„ÛŒØ¯ Ù‡Ø´ØªÚ¯ Ù‡ÙˆØ´Ù…Ù†Ø¯"""
    
    def __init__(self, api_manager, sheets_manager):
        super().__init__("HashtagGenerator", api_manager, sheets_manager)
        self.hashtag_performance = {}
    
    async def execute(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """ØªÙˆÙ„ÛŒØ¯ Ù‡Ø´ØªÚ¯â€ŒÙ‡Ø§"""
        try:
            content = task.get('content', '')
            platform = task.get('platform', 'twitter')
            count = task.get('count', 3)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙˆØ¶ÙˆØ¹Ø§Øª
            topics = await self._extract_topics(content)
            
            # ØªÙˆÙ„ÛŒØ¯ Ù‡Ø´ØªÚ¯â€ŒÙ‡Ø§
            hashtags = await self._generate_hashtags(topics, count)
            
            # Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ
            ranked_hashtags = await self._rank_hashtags(hashtags)
            
            result = {
                'hashtags': ranked_hashtags[:count],
                'all_suggestions': ranked_hashtags,
                'topics_detected': topics
            }
            
            await self._record_task(task, result, True)
            return result
            
        except Exception as e:
            logger.error(f"âŒ HashtagGenerator error: {e}")
            return {'error': str(e)}
    
    async def _extract_topics(self, content: str) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙˆØ¶ÙˆØ¹Ø§Øª"""
        # Ú©Ù„Ù…Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ Ù…Ù‡Ù…
        keywords = []
        words = content.split()
        
        # Ú©Ù„Ù…Ø§ØªÛŒ Ú©Ù‡ Ø¨Ø§ Ø­Ø±Ù Ø¨Ø²Ø±Ú¯ Ø´Ø±ÙˆØ¹ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯ (Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ø§Ø³Ù…â€ŒÙ‡Ø§ÛŒ Ø®Ø§Øµ)
        for word in words:
            if word[0].isupper() and len(word) > 3:
                keywords.append(word)
        
        return keywords[:5]
    
    async def _generate_hashtags(self, topics: List[str], count: int) -> List[str]:
        """ØªÙˆÙ„ÛŒØ¯ Ù‡Ø´ØªÚ¯â€ŒÙ‡Ø§"""
        hashtags = []
        
        # Ù‡Ø´ØªÚ¯â€ŒÙ‡Ø§ÛŒ Ø¹Ù…ÙˆÙ…ÛŒ Ù¾Ø±Ú©Ø§Ø±Ø¨Ø±Ø¯
        common_hashtags = ['#AI', '#Tech', '#Innovation', '#ML', '#DataScience']
        
        # Ù‡Ø´ØªÚ¯ Ø§Ø² Ù…ÙˆØ¶ÙˆØ¹Ø§Øª
        for topic in topics:
            hashtags.append(f"#{topic.replace(' ', '')}")
        
        # Ø§ÙØ²ÙˆØ¯Ù† Ù‡Ø´ØªÚ¯â€ŒÙ‡Ø§ÛŒ Ø¹Ù…ÙˆÙ…ÛŒ
        hashtags.extend(common_hashtags)
        
        return list(set(hashtags))  # Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±ÛŒâ€ŒÙ‡Ø§
    
    async def _rank_hashtags(self, hashtags: List[str]) -> List[Dict]:
        """Ø±ØªØ¨Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ù‡Ø´ØªÚ¯â€ŒÙ‡Ø§"""
        ranked = []
        
        for tag in hashtags:
            # Ø§Ù…ØªÛŒØ§Ø² Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡
            score = len(tag) * 10  # Ø³Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡
            
            ranked.append({
                'hashtag': tag,
                'score': score,
                'estimated_reach': score * 100
            })
        
        return sorted(ranked, key=lambda x: x['score'], reverse=True)


class SentimentAnalysisAgent(BaseSpecializedAgent):
    """Ø§ÛŒØ¬Ù†Øª 6: ØªØ­Ù„ÛŒÙ„ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø§Ø­Ø³Ø§Ø³Ø§Øª"""
    
    def __init__(self, api_manager, sheets_manager):
        super().__init__("SentimentAnalysis", api_manager, sheets_manager)
    
    async def execute(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """ØªØ­Ù„ÛŒÙ„ Ø§Ø­Ø³Ø§Ø³Ø§Øª"""
        try:
            text = task.get('text', '')
            
            # ØªØ­Ù„ÛŒÙ„
            analysis = await self._analyze(text)
            
            result = {
                'overall_sentiment': analysis['sentiment'],
                'confidence': analysis['confidence'],
                'emotions': analysis['emotions'],
                'tone': analysis['tone'],
                'subjectivity': analysis['subjectivity']
            }
            
            await self._record_task(task, result, True)
            return result
            
        except Exception as e:
            logger.error(f"âŒ SentimentAnalysis error: {e}")
            return {'error': str(e)}
    
    async def _analyze(self, text: str) -> Dict:
        """ØªØ­Ù„ÛŒÙ„ Ù…ØªÙ†"""
        positive_words = ['good', 'great', 'awesome', 'excellent', 'amazing', 'love', 'best']
        negative_words = ['bad', 'terrible', 'awful', 'worst', 'hate', 'poor']
        
        text_lower = text.lower()
        
        pos_count = sum(1 for w in positive_words if w in text_lower)
        neg_count = sum(1 for w in negative_words if w in text_lower)
        
        if pos_count > neg_count:
            sentiment = 'positive'
            confidence = min(pos_count / 10, 1.0)
        elif neg_count > pos_count:
            sentiment = 'negative'
            confidence = min(neg_count / 10, 1.0)
        else:
            sentiment = 'neutral'
            confidence = 0.5
        
        return {
            'sentiment': sentiment,
            'confidence': confidence,
            'emotions': {
                'joy': pos_count * 10,
                'anger': neg_count * 10
            },
            'tone': 'professional' if len(text) > 100 else 'casual',
            'subjectivity': 0.6
        }


class FactCheckerAgent(BaseSpecializedAgent):
    """Ø§ÛŒØ¬Ù†Øª 7: Ø¨Ø±Ø±Ø³ÛŒ ØµØ­Øª Ø§Ø·Ù„Ø§Ø¹Ø§Øª"""
    
    def __init__(self, api_manager, sheets_manager):
        super().__init__("FactChecker", api_manager, sheets_manager)
        self.verified_facts = {}
    
    async def execute(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """Ø¨Ø±Ø±Ø³ÛŒ ØµØ­Øª"""
        try:
            claim = task.get('claim', '')
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø¯Ø¹Ø§Ù‡Ø§
            claims = await self._extract_claims(claim)
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ù‡Ø± Ø§Ø¯Ø¹Ø§
            verifications = []
            for c in claims:
                verification = await self._verify_claim(c)
                verifications.append(verification)
            
            result = {
                'claims': claims,
                'verifications': verifications,
                'overall_credibility': await self._calculate_credibility(verifications)
            }
            
            await self._record_task(task, result, True)
            return result
            
        except Exception as e:
            logger.error(f"âŒ FactChecker error: {e}")
            return {'error': str(e)}
    
    async def _extract_claims(self, text: str) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø¯Ø¹Ø§Ù‡Ø§"""
        # Ø¬Ù…Ù„Ø§ØªÛŒ Ú©Ù‡ Ø´Ø§Ù…Ù„ Ø¢Ù…Ø§Ø± ÛŒØ§ Ø§Ø¯Ø¹Ø§ÛŒ Ù‚Ø·Ø¹ÛŒ Ù‡Ø³ØªÙ†Ø¯
        claims = []
        sentences = text.split('.')
        
        for sentence in sentences:
            # Ø§Ú¯Ø± Ø´Ø§Ù…Ù„ Ø¹Ø¯Ø¯ Ø¨Ø§Ø´Ø¯
            if any(char.isdigit() for char in sentence):
                claims.append(sentence.strip())
        
        return claims if claims else [text]
    
    async def _verify_claim(self, claim: str) -> Dict:
        """Ø¨Ø±Ø±Ø³ÛŒ ÛŒÚ© Ø§Ø¯Ø¹Ø§"""
        # Ø¯Ø± ÙˆØ§Ù‚Ø¹ÛŒØªØŒ Ø§Ø² APIâ€ŒÙ‡Ø§ÛŒ fact-checking Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
        return {
            'claim': claim,
            'status': 'unverified',  # verified, false, unverified
            'confidence': 0.5,
            'sources': []
        }
    
    async def _calculate_credibility(self, verifications: List[Dict]) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø¹ØªØ¨Ø§Ø± Ú©Ù„ÛŒ"""
        if not verifications:
            return 0.5
        
        verified_count = sum(1 for v in verifications if v['status'] == 'verified')
        return verified_count / len(verifications)


class LanguageDetectorAgent(BaseSpecializedAgent):
    """Ø§ÛŒØ¬Ù†Øª 8: ØªØ´Ø®ÛŒØµ Ø²Ø¨Ø§Ù† Ùˆ ØªØ±Ø¬Ù…Ù‡"""
    
    def __init__(self, api_manager, sheets_manager):
        super().__init__("LanguageDetector", api_manager, sheets_manager)
    
    async def execute(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """ØªØ´Ø®ÛŒØµ Ø²Ø¨Ø§Ù†"""
        try:
            text = task.get('text', '')
            
            # ØªØ´Ø®ÛŒØµ
            language = await self._detect_language(text)
            
            # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø²Ø¨Ø§Ù†
            language_info = await self._get_language_info(language)
            
            result = {
                'detected_language': language,
                'confidence': 0.9,
                'language_info': language_info,
                'should_translate': language != 'en'
            }
            
            await self._record_task(task, result, True)
            return result
            
        except Exception as e:
            logger.error(f"âŒ LanguageDetector error: {e}")
            return {'error': str(e)}
    
    async def _detect_language(self, text: str) -> str:
        """ØªØ´Ø®ÛŒØµ Ø²Ø¨Ø§Ù†"""
        # ÙØ§Ø±Ø³ÛŒ
        if re.search(r'[\u0600-\u06FF]', text):
            return 'fa'
        # Ø¹Ø±Ø¨ÛŒ
        elif re.search(r'[\u0600-\u06FF]', text):
            return 'ar'
        # Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
        elif re.search(r'[a-zA-Z]', text):
            return 'en'
        
        return 'unknown'
    
    async def _get_language_info(self, language: str) -> Dict:
        """Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø²Ø¨Ø§Ù†"""
        info = {
            'en': {'name': 'English', 'direction': 'ltr', 'common': True},
            'fa': {'name': 'Persian', 'direction': 'rtl', 'common': True},
            'ar': {'name': 'Arabic', 'direction': 'rtl', 'common': True}
        }
        
        return info.get(language, {'name': 'Unknown', 'direction': 'ltr', 'common': False})


class AudienceSegmentationAgent(BaseSpecializedAgent):
    """Ø§ÛŒØ¬Ù†Øª 9: ØªÙ‚Ø³ÛŒÙ…â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø®Ø§Ø·Ø¨Ø§Ù†"""
    
    def __init__(self, api_manager, sheets_manager):
        super().__init__("AudienceSegmentation", api_manager, sheets_manager)
        self.segments = {}
    
    async def execute(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """ØªÙ‚Ø³ÛŒÙ…â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø®Ø§Ø·Ø¨Ø§Ù†"""
        try:
            user_data = task.get('user_data', [])
            
            # ØªÙ‚Ø³ÛŒÙ…â€ŒØ¨Ù†Ø¯ÛŒ
            segments = await self._segment_users(user_data)
            
            # ØªØ­Ù„ÛŒÙ„ Ù‡Ø± segment
            analysis = await self._analyze_segments(segments)
            
            result = {
                'segments': segments,
                'analysis': analysis,
                'recommendations': await self._get_segment_recommendations(segments)
            }
            
            await self._record_task(task, result, True)
            return result
            
        except Exception as e:
            logger.error(f"âŒ AudienceSegmentation error: {e}")
            return {'error': str(e)}
    
    async def _segment_users(self, user_data: List[Dict]) -> Dict:
        """ØªÙ‚Ø³ÛŒÙ…â€ŒØ¨Ù†Ø¯ÛŒ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†"""
        segments = {
            'highly_engaged': [],
            'moderately_engaged': [],
            'passive': [],
            'new': []
        }
        
        for user in user_data:
            engagement_score = user.get('engagement_score', 0)
            
            if engagement_score > 80:
                segments['highly_engaged'].append(user)
            elif engagement_score > 50:
                segments['moderately_engaged'].append(user)
            elif engagement_score > 20:
                segments['passive'].append(user)
            else:
                segments['new'].append(user)
        
        return segments
    
    async def _analyze_segments(self, segments: Dict) -> Dict:
        """ØªØ­Ù„ÛŒÙ„ segments"""
        return {
            segment_name: {
                'count': len(users),
                'percentage': len(users) / sum(len(s) for s in segments.values()) * 100 if segments else 0
            }
            for segment_name, users in segments.items()
        }
    
    async def _get_segment_recommendations(self, segments: Dict) -> List[str]:
        """ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ segment"""
        recs = []
        
        if len(segments['highly_engaged']) > 0:
            recs.append("ØªØ´ÙˆÛŒÙ‚ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† highly engaged Ø¨Ø±Ø§ÛŒ share Ú©Ø±Ø¯Ù† Ù…Ø­ØªÙˆØ§")
        
        if len(segments['passive']) > len(segments['moderately_engaged']):
            recs.append("Ù…Ø­ØªÙˆØ§ÛŒ Ø¬Ø°Ø§Ø¨â€ŒØªØ± Ø¨Ø±Ø§ÛŒ ÙØ¹Ø§Ù„ Ú©Ø±Ø¯Ù† Ú©Ø§Ø±Ø¨Ø±Ø§Ù† passive")
        
        return recs


class CompetitorMonitorAgent(BaseSpecializedAgent):
    """Ø§ÛŒØ¬Ù†Øª 10: Ù†Ø¸Ø§Ø±Øª Ø¨Ø± Ø±Ù‚Ø¨Ø§"""
    
    def __init__(self, api_manager, sheets_manager):
        super().__init__("CompetitorMonitor", api_manager, sheets_manager)
        self.competitors = []
    
    async def execute(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """Ù†Ø¸Ø§Ø±Øª Ø¨Ø± Ø±Ù‚Ø¨Ø§"""
        try:
            competitor = task.get('competitor', '')
            
            # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡
            data = await self._collect_competitor_data(competitor)
            
            # ØªØ­Ù„ÛŒÙ„
            analysis = await self._analyze_competitor(data)
            
            # insights
            insights = await self._extract_insights(analysis)
            
            result = {
                'competitor': competitor,
                'data': data,
                'analysis': analysis,
                'insights': insights,
                'action_items': await self._generate_action_items(insights)
            }
            
            await self._record_task(task, result, True)
            return result
            
        except Exception as e:
            logger.error(f"âŒ CompetitorMonitor error: {e}")
            return {'error': str(e)}
    
    async def _collect_competitor_data(self, competitor: str) -> Dict:
        """Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡ Ø±Ù‚ÛŒØ¨"""
        # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ
        return {
            'follower_count': 50000,
            'posting_frequency': '3-4 posts/day',
            'engagement_rate': '4.5%',
            'top_topics': ['AI', 'ML', 'Tech'],
            'best_performing_content': []
        }
    
    async def _analyze_competitor(self, data: Dict) -> Dict:
        """ØªØ­Ù„ÛŒÙ„ Ø±Ù‚ÛŒØ¨"""
        return {
            'strengths': ['High engagement', 'Consistent posting'],
            'weaknesses': ['Limited topic diversity'],
            'opportunities': ['Unexplored topics', 'Video content']
        }
    
    async def _extract_insights(self, analysis: Dict) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ insights"""
        return [
            "Ø±Ù‚ÛŒØ¨ Ø¯Ø± ÙˆÛŒØ¯ÛŒÙˆ Ø¶Ø¹ÛŒÙ Ø§Ø³Øª - ÙØ±ØµØª Ø®ÙˆØ¨",
            "Ù…Ø­ØªÙˆØ§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ engagement Ø¨Ø§Ù„Ø§ÛŒÛŒ Ø¯Ø§Ø±Ø¯"
        ]
    
    async def _generate_action_items(self, insights: List[str]) -> List[str]:
        """ØªÙˆÙ„ÛŒØ¯ Ø§Ù‚Ø¯Ø§Ù…Ø§Øª"""
        return [
            "Ø§ÙØ²Ø§ÛŒØ´ Ù…Ø­ØªÙˆØ§ÛŒ ÙˆÛŒØ¯ÛŒÙˆÛŒÛŒ",
            "ØªÙ…Ø±Ú©Ø² Ø¨ÛŒØ´ØªØ± Ø±ÙˆÛŒ Ø¢Ù…ÙˆØ²Ø´"
        ]


# Ø§Ø±Ú©Ø³ØªØ±Ø§ØªÙˆØ± Ø§ÛŒØ¬Ù†Øªâ€ŒÙ‡Ø§ÛŒ ØªØ®ØµØµÛŒ
class SpecializedAgentOrchestrator:
    """Ù…Ø¯ÛŒØ±ÛŒØª ØªÙ…Ø§Ù… Ø§ÛŒØ¬Ù†Øªâ€ŒÙ‡Ø§ÛŒ ØªØ®ØµØµÛŒ"""
    
    def __init__(self, api_manager, sheets_manager):
        self.api_manager = api_manager
        self.sheets_manager = sheets_manager
        self.agents = {}
        
    async def initialize(self):
        """Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ ØªÙ…Ø§Ù… Ø§ÛŒØ¬Ù†Øªâ€ŒÙ‡Ø§"""
        logger.info("ğŸš€ Initializing 10 specialized agents...")
        
        self.agents['content_optimization'] = ContentOptimizationAgent(
            self.api_manager, self.sheets_manager
        )
        self.agents['engagement_predictor'] = EngagementPredictorAgent(
            self.api_manager, self.sheets_manager
        )
        self.agents['trend_analysis'] = TrendAnalysisAgent(
            self.api_manager, self.sheets_manager
        )
        self.agents['scheduling_optimizer'] = SchedulingOptimizerAgent(
            self.api_manager, self.sheets_manager
        )
        self.agents['hashtag_generator'] = HashtagGeneratorAgent(
            self.api_manager, self.sheets_manager
        )
        self.agents['sentiment_analysis'] = SentimentAnalysisAgent(
            self.api_manager, self.sheets_manager
        )
        self.agents['fact_checker'] = FactCheckerAgent(
            self.api_manager, self.sheets_manager
        )
        self.agents['language_detector'] = LanguageDetectorAgent(
            self.api_manager, self.sheets_manager
        )
        self.agents['audience_segmentation'] = AudienceSegmentationAgent(
            self.api_manager, self.sheets_manager
        )
        self.agents['competitor_monitor'] = CompetitorMonitorAgent(
            self.api_manager, self.sheets_manager
        )
        
        logger.info(f"âœ… All {len(self.agents)} specialized agents initialized!")
    
    def get_agent(self, agent_name: str) -> Optional[BaseSpecializedAgent]:
        """Ø¯Ø±ÛŒØ§ÙØª ÛŒÚ© Ø§ÛŒØ¬Ù†Øª"""
        return self.agents.get(agent_name)
    
    async def execute_task(self, agent_name: str, task: Dict) -> Dict:
        """Ø§Ø¬Ø±Ø§ÛŒ ØªØ³Ú© ØªÙˆØ³Ø· ÛŒÚ© Ø§ÛŒØ¬Ù†Øª"""
        agent = self.get_agent(agent_name)
        if agent:
            return await agent.execute(task)
        return {'error': f'Agent {agent_name} not found'}
    
    def get_all_performance(self) -> Dict:
        """Ø¹Ù…Ù„Ú©Ø±Ø¯ ØªÙ…Ø§Ù… Ø§ÛŒØ¬Ù†Øªâ€ŒÙ‡Ø§"""
        return {
            name: agent.get_performance()
            for name, agent in self.agents.items()
        }
