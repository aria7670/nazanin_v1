"""
Behavioral Learning Agents
Ø§ÛŒØ¬Ù†Øªâ€ŒÙ‡Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø§Ø² Ø±ÙØªØ§Ø± Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø¨Ø±Ø§ÛŒ Ø§Ù†Ø³Ø§Ù†ÛŒâ€ŒØªØ± Ø´Ø¯Ù†
"""

import asyncio
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
from collections import defaultdict, deque
import json
import numpy as np

logger = logging.getLogger(__name__)


class UserBehaviorTracker:
    """Ø±Ø¯ÛŒØ§Ø¨ÛŒ Ø±ÙØªØ§Ø± Ú©Ø§Ø±Ø¨Ø±Ø§Ù†"""
    
    def __init__(self, user_id: str):
        self.user_id = user_id
        self.interactions = deque(maxlen=1000)  # 1000 ØªØ¹Ø§Ù…Ù„ Ø§Ø®ÛŒØ±
        self.preferences = {}
        self.patterns = {}
        self.personality_profile = {}
        
    def record_interaction(self, interaction: Dict):
        """Ø«Ø¨Øª ÛŒÚ© ØªØ¹Ø§Ù…Ù„"""
        interaction['timestamp'] = datetime.now().isoformat()
        self.interactions.append(interaction)
        
        # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø§Ù„Ú¯ÙˆÙ‡Ø§
        self._update_patterns(interaction)
    
    def _update_patterns(self, interaction: Dict):
        """Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø±ÙØªØ§Ø±ÛŒ"""
        
        # Ø§Ù„Ú¯ÙˆÛŒ Ø²Ù…Ø§Ù†ÛŒ
        hour = datetime.now().hour
        if 'time_patterns' not in self.patterns:
            self.patterns['time_patterns'] = defaultdict(int)
        self.patterns['time_patterns'][hour] += 1
        
        # Ø§Ù„Ú¯ÙˆÛŒ Ù…ÙˆØ¶ÙˆØ¹ÛŒ
        if 'topic' in interaction:
            if 'topic_interests' not in self.patterns:
                self.patterns['topic_interests'] = defaultdict(int)
            self.patterns['topic_interests'][interaction['topic']] += 1
        
        # Ø§Ù„Ú¯ÙˆÛŒ Ø·ÙˆÙ„ Ù¾ÛŒØ§Ù…
        if 'message_length' in interaction:
            if 'message_lengths' not in self.patterns:
                self.patterns['message_lengths'] = []
            self.patterns['message_lengths'].append(interaction['message_length'])
            
            # Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ† Ø¢Ø®Ø±ÛŒÙ† 100 ØªØ§
            if len(self.patterns['message_lengths']) > 100:
                self.patterns['message_lengths'] = self.patterns['message_lengths'][-100:]
    
    def get_active_hours(self) -> List[int]:
        """Ø³Ø§Ø¹Ø§Øª ÙØ¹Ø§Ù„ÛŒØª Ú©Ø§Ø±Ø¨Ø±"""
        if 'time_patterns' not in self.patterns:
            return []
        
        time_data = self.patterns['time_patterns']
        sorted_hours = sorted(time_data.items(), key=lambda x: x[1], reverse=True)
        
        return [hour for hour, count in sorted_hours[:5]]
    
    def get_favorite_topics(self) -> List[str]:
        """Ù…ÙˆØ¶ÙˆØ¹Ø§Øª Ù…ÙˆØ±Ø¯ Ø¹Ù„Ø§Ù‚Ù‡"""
        if 'topic_interests' not in self.patterns:
            return []
        
        topic_data = self.patterns['topic_interests']
        sorted_topics = sorted(topic_data.items(), key=lambda x: x[1], reverse=True)
        
        return [topic for topic, count in sorted_topics[:10]]
    
    def get_preferred_message_length(self) -> str:
        """Ø·ÙˆÙ„ Ù¾ÛŒØ§Ù… ØªØ±Ø¬ÛŒØ­ÛŒ Ú©Ø§Ø±Ø¨Ø±"""
        if 'message_lengths' not in self.patterns or not self.patterns['message_lengths']:
            return 'medium'
        
        avg_length = np.mean(self.patterns['message_lengths'])
        
        if avg_length < 50:
            return 'short'
        elif avg_length < 200:
            return 'medium'
        else:
            return 'long'
    
    def build_profile(self) -> Dict[str, Any]:
        """Ø³Ø§Ø®Øª Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ú©Ø§Ù…Ù„ Ú©Ø§Ø±Ø¨Ø±"""
        return {
            'user_id': self.user_id,
            'total_interactions': len(self.interactions),
            'active_hours': self.get_active_hours(),
            'favorite_topics': self.get_favorite_topics(),
            'preferred_length': self.get_preferred_message_length(),
            'patterns': self.patterns,
            'last_interaction': self.interactions[-1] if self.interactions else None
        }


class ConversationStyleLearner:
    """ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø³Ø¨Ú© Ù…Ú©Ø§Ù„Ù…Ù‡"""
    
    def __init__(self):
        self.conversation_history = deque(maxlen=500)
        self.successful_patterns = []
        self.failed_patterns = []
        
    async def learn_from_conversation(self, messages: List[Dict], 
                                      outcome: str, feedback: Optional[Dict] = None):
        """ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø§Ø² ÛŒÚ© Ù…Ú©Ø§Ù„Ù…Ù‡"""
        
        conversation = {
            'messages': messages,
            'outcome': outcome,  # 'success', 'neutral', 'failure'
            'feedback': feedback,
            'timestamp': datetime.now().isoformat(),
            'features': self._extract_features(messages)
        }
        
        self.conversation_history.append(conversation)
        
        # Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ
        if outcome == 'success':
            self.successful_patterns.append(conversation['features'])
        elif outcome == 'failure':
            self.failed_patterns.append(conversation['features'])
        
        logger.info(f"ğŸ“š ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø§Ø² Ù…Ú©Ø§Ù„Ù…Ù‡: {outcome}")
    
    def _extract_features(self, messages: List[Dict]) -> Dict[str, Any]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ú©Ø§Ù„Ù…Ù‡"""
        features = {
            'message_count': len(messages),
            'avg_length': np.mean([len(m.get('content', '')) for m in messages]),
            'has_emoji': any('ğŸ˜€' in m.get('content', '') or 'ğŸ˜Š' in m.get('content', '') for m in messages),
            'topics': list(set([m.get('topic') for m in messages if m.get('topic')])),
            'formality': self._detect_formality(messages),
            'response_time_avg': self._calc_avg_response_time(messages)
        }
        
        return features
    
    def _detect_formality(self, messages: List[Dict]) -> str:
        """ØªØ´Ø®ÛŒØµ Ø³Ø·Ø­ Ø±Ø³Ù…ÛŒ Ø¨ÙˆØ¯Ù†"""
        formal_words = ['please', 'thank you', 'kindly', 'Ù„Ø·ÙØ§', 'Ù…ØªØ´Ú©Ø±Ù…', 'Ù…Ù…Ù†ÙˆÙ†']
        casual_words = ['hey', 'cool', 'awesome', 'lol', 'Ø³Ù„Ø§Ù…', 'Ø®ÙˆØ¨ÛŒ', 'Ø¹Ø§Ù„ÛŒÙ‡']
        
        formal_count = 0
        casual_count = 0
        
        for msg in messages:
            content = msg.get('content', '').lower()
            formal_count += sum(1 for w in formal_words if w in content)
            casual_count += sum(1 for w in casual_words if w in content)
        
        if formal_count > casual_count:
            return 'formal'
        elif casual_count > formal_count:
            return 'casual'
        return 'neutral'
    
    def _calc_avg_response_time(self, messages: List[Dict]) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø²Ù…Ø§Ù† Ù¾Ø§Ø³Ø®"""
        times = []
        
        for i in range(1, len(messages)):
            if 'timestamp' in messages[i] and 'timestamp' in messages[i-1]:
                try:
                    t1 = datetime.fromisoformat(messages[i-1]['timestamp'])
                    t2 = datetime.fromisoformat(messages[i]['timestamp'])
                    diff = (t2 - t1).total_seconds()
                    times.append(diff)
                except:
                    pass
        
        return np.mean(times) if times else 0.0
    
    def get_best_practices(self) -> Dict[str, Any]:
        """Ø¨Ù‡ØªØ±ÛŒÙ† Ø´ÛŒÙˆÙ‡â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ"""
        
        if not self.successful_patterns:
            return {}
        
        # ØªØ­Ù„ÛŒÙ„ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù…ÙˆÙÙ‚
        avg_message_count = np.mean([p['message_count'] for p in self.successful_patterns])
        avg_length = np.mean([p['avg_length'] for p in self.successful_patterns])
        emoji_usage = np.mean([1 if p['has_emoji'] else 0 for p in self.successful_patterns])
        
        formality_dist = defaultdict(int)
        for p in self.successful_patterns:
            formality_dist[p['formality']] += 1
        
        best_formality = max(formality_dist.items(), key=lambda x: x[1])[0] if formality_dist else 'neutral'
        
        return {
            'optimal_message_count': int(avg_message_count),
            'optimal_message_length': int(avg_length),
            'should_use_emoji': emoji_usage > 0.5,
            'preferred_formality': best_formality,
            'success_rate': len(self.successful_patterns) / len(self.conversation_history) if self.conversation_history else 0
        }


class PersonalityAdapter:
    """ØªØ·Ø¨ÛŒÙ‚ Ø´Ø®ØµÛŒØª Ø¨Ø§ Ù…Ø®Ø§Ø·Ø¨"""
    
    def __init__(self):
        self.user_profiles = {}  # user_id -> UserBehaviorTracker
        self.style_learner = ConversationStyleLearner()
        
    def get_or_create_profile(self, user_id: str) -> UserBehaviorTracker:
        """Ø¯Ø±ÛŒØ§ÙØª ÛŒØ§ Ø³Ø§Ø®Øª Ù¾Ø±ÙˆÙØ§ÛŒÙ„ Ú©Ø§Ø±Ø¨Ø±"""
        if user_id not in self.user_profiles:
            self.user_profiles[user_id] = UserBehaviorTracker(user_id)
        return self.user_profiles[user_id]
    
    async def adapt_response(self, user_id: str, message: str, 
                            base_response: str) -> str:
        """ØªØ·Ø¨ÛŒÙ‚ Ù¾Ø§Ø³Ø® Ø¨Ø§ Ø´Ø®ØµÛŒØª Ú©Ø§Ø±Ø¨Ø±"""
        
        profile = self.get_or_create_profile(user_id)
        
        # ØªØ­Ù„ÛŒÙ„ ØªØ±Ø¬ÛŒØ­Ø§Øª Ú©Ø§Ø±Ø¨Ø±
        preferred_length = profile.get_preferred_message_length()
        favorite_topics = profile.get_favorite_topics()
        
        # ØªØ·Ø¨ÛŒÙ‚ Ø·ÙˆÙ„
        if preferred_length == 'short' and len(base_response) > 200:
            # Ø®Ù„Ø§ØµÙ‡ Ú©Ø±Ø¯Ù†
            adapted_response = await self._summarize(base_response, max_length=150)
        elif preferred_length == 'long' and len(base_response) < 100:
            # ØªÙˆØ³Ø¹Ù‡
            adapted_response = await self._expand(base_response)
        else:
            adapted_response = base_response
        
        # Ø§ÙØ²ÙˆØ¯Ù† Ø§Ø±Ø¬Ø§Ø¹ Ø¨Ù‡ Ù…ÙˆØ¶ÙˆØ¹Ø§Øª Ù…ÙˆØ±Ø¯ Ø¹Ù„Ø§Ù‚Ù‡ (Ø¯Ø± ØµÙˆØ±Øª Ø§Ù…Ú©Ø§Ù†)
        if favorite_topics and any(topic in message.lower() for topic in favorite_topics):
            adapted_response = self._add_personal_touch(adapted_response, favorite_topics)
        
        return adapted_response
    
    async def _summarize(self, text: str, max_length: int = 150) -> str:
        """Ø®Ù„Ø§ØµÙ‡ Ú©Ø±Ø¯Ù† Ù…ØªÙ†"""
        if len(text) <= max_length:
            return text
        
        # Ø®Ù„Ø§ØµÙ‡ Ø³Ø§Ø¯Ù‡: Ø§ÙˆÙ„ÛŒÙ† Ø¬Ù…Ù„Ù‡ + Ø¢Ø®Ø±ÛŒÙ† Ø¬Ù…Ù„Ù‡
        sentences = text.split('. ')
        if len(sentences) > 2:
            return f"{sentences[0]}. ... {sentences[-1]}"
        
        return text[:max_length] + "..."
    
    async def _expand(self, text: str) -> str:
        """ØªÙˆØ³Ø¹Ù‡ Ù…ØªÙ†"""
        # Ø§ÙØ²ÙˆØ¯Ù† Ø¬Ø²Ø¦ÛŒØ§Øª Ø¨ÛŒØ´ØªØ± (Ø³Ø§Ø¯Ù‡)
        expansions = [
            "\n\nØ§ÛŒÙ† Ù…ÙˆØ¶ÙˆØ¹ Ø¨Ø³ÛŒØ§Ø± Ø¬Ø§Ù„Ø¨ Ø§Ø³Øª.",
            "\n\nØ§Ù…ÛŒØ¯ÙˆØ§Ø±Ù… Ø§ÛŒÙ† Ù¾Ø§Ø³Ø® Ù…ÙÛŒØ¯ Ø¨Ø§Ø´Ø¯.",
            "\n\nØ§Ú¯Ø± Ø³ÙˆØ§Ù„ Ø¯ÛŒÚ¯Ø±ÛŒ Ø¯Ø§Ø´ØªÛŒØ¯ØŒ Ø¨Ù¾Ø±Ø³ÛŒØ¯."
        ]
        
        return text + expansions[0]
    
    def _add_personal_touch(self, response: str, topics: List[str]) -> str:
        """Ø§ÙØ²ÙˆØ¯Ù† Ù„Ù…Ø³ Ø´Ø®ØµÛŒ"""
        topic = topics[0]
        personal_notes = [
            f"\n\n(Ù…ÛŒâ€ŒØ¯Ø§Ù†Ù… Ú©Ù‡ Ø¹Ù„Ø§Ù‚Ù‡â€ŒÙ…Ù†Ø¯ Ø¨Ù‡ {topic} Ù‡Ø³ØªÛŒØ¯)",
            f"\n\nØ¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø¹Ù„Ø§Ù‚Ù‡ Ø´Ù…Ø§ Ø¨Ù‡ {topic}...",
        ]
        
        return response + personal_notes[0]
    
    async def record_interaction(self, user_id: str, interaction: Dict):
        """Ø«Ø¨Øª ØªØ¹Ø§Ù…Ù„"""
        profile = self.get_or_create_profile(user_id)
        profile.record_interaction(interaction)
    
    def get_statistics(self) -> Dict[str, Any]:
        """Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ"""
        return {
            'total_users': len(self.user_profiles),
            'total_interactions': sum(len(p.interactions) for p in self.user_profiles.values()),
            'best_practices': self.style_learner.get_best_practices()
        }


class EmotionalIntelligence:
    """Ù‡ÙˆØ´ Ø§Ø­Ø³Ø§Ø³ÛŒ"""
    
    def __init__(self):
        self.emotional_memory = deque(maxlen=200)
        self.empathy_model = self._initialize_empathy_model()
        
    def _initialize_empathy_model(self) -> Dict[str, Dict]:
        """Ù…Ø¯Ù„ Ù‡Ù…Ø¯Ù„ÛŒ"""
        return {
            'sad': {
                'keywords': ['sad', 'depressed', 'down', 'ØºÙ…Ú¯ÛŒÙ†', 'Ù†Ø§Ø±Ø§Ø­Øª', 'ğŸ˜¢', 'ğŸ˜­'],
                'response_style': 'supportive',
                'phrases': [
                    "Ù…ØªØ§Ø³ÙÙ… Ú©Ù‡ Ø§ÛŒÙ† Ø­Ø³ Ø±Ùˆ Ø¯Ø§Ø±ÛŒ",
                    "Ø¯Ø±Ú© Ù…ÛŒâ€ŒÚ©Ù†Ù… Ú†Ù‚Ø¯Ø± Ø³Ø®ØªÙ‡",
                    "I'm sorry you're going through this"
                ]
            },
            'happy': {
                'keywords': ['happy', 'excited', 'great', 'Ø®ÙˆØ´Ø­Ø§Ù„', 'Ø¹Ø§Ù„ÛŒ', 'ğŸ˜Š', 'ğŸ‰'],
                'response_style': 'enthusiastic',
                'phrases': [
                    "Ú†Ù‡ Ø®ÙˆØ¨!",
                    "Ø®ÛŒÙ„ÛŒ Ø®ÙˆØ´Ø­Ø§Ù„Ù… Ø¨Ø±Ø§Øª!",
                    "That's wonderful!"
                ]
            },
            'angry': {
                'keywords': ['angry', 'mad', 'frustrated', 'Ø¹ØµØ¨Ø§Ù†ÛŒ', 'Ø¹ØµØ¨ÛŒ', 'ğŸ˜¡'],
                'response_style': 'calming',
                'phrases': [
                    "Ø¯Ø±Ú© Ù…ÛŒâ€ŒÚ©Ù†Ù… Ú†Ø±Ø§ Ù†Ø§Ø±Ø§Ø­ØªÛŒ",
                    "Ø­Ù‚ Ø¯Ø§Ø±ÛŒ Ú©Ù‡ Ø§Ø­Ø³Ø§Ø³ Ú©Ù†ÛŒ",
                    "I understand your frustration"
                ]
            },
            'confused': {
                'keywords': ['confused', 'unclear', 'Ú¯ÛŒØ¬', 'Ù†Ù…ÛŒâ€ŒÙÙ‡Ù…Ù…', 'ğŸ¤”'],
                'response_style': 'clarifying',
                'phrases': [
                    "Ø¨Ø°Ø§Ø± ÙˆØ§Ø¶Ø­â€ŒØªØ± ØªÙˆØ¶ÛŒØ­ Ø¨Ø¯Ù…",
                    "Ø¨Ø¨ÛŒÙ†ØŒ Ø§ÛŒÙ† Ø·ÙˆØ±ÛŒ Ø±Ø§Ø­Øªâ€ŒØªØ±Ù‡",
                    "Let me clarify that"
                ]
            }
        }
    
    async def detect_emotion(self, message: str) -> Dict[str, Any]:
        """ØªØ´Ø®ÛŒØµ Ø§Ø­Ø³Ø§Ø³Ø§Øª"""
        detected_emotions = {}
        
        message_lower = message.lower()
        
        for emotion, model in self.empathy_model.items():
            score = sum(1 for keyword in model['keywords'] if keyword in message_lower)
            if score > 0:
                detected_emotions[emotion] = score
        
        if not detected_emotions:
            return {'emotion': 'neutral', 'confidence': 0.5}
        
        primary_emotion = max(detected_emotions.items(), key=lambda x: x[1])
        
        return {
            'emotion': primary_emotion[0],
            'confidence': min(primary_emotion[1] / 3, 1.0),
            'all_emotions': detected_emotions
        }
    
    async def generate_empathetic_response(self, message: str, 
                                          base_response: str) -> str:
        """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ù‡Ù…Ø¯Ù„Ø§Ù†Ù‡"""
        
        emotion_data = await self.detect_emotion(message)
        emotion = emotion_data['emotion']
        
        if emotion == 'neutral':
            return base_response
        
        # Ø§ÙØ²ÙˆØ¯Ù† Ø¹Ø¨Ø§Ø±Øª Ù‡Ù…Ø¯Ù„Ø§Ù†Ù‡
        empathy_phrase = np.random.choice(self.empathy_model[emotion]['phrases'])
        
        empathetic_response = f"{empathy_phrase}\n\n{base_response}"
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø­Ø§ÙØ¸Ù‡ Ø§Ø­Ø³Ø§Ø³ÛŒ
        self.emotional_memory.append({
            'message': message[:100],
            'emotion': emotion,
            'response': empathetic_response[:100],
            'timestamp': datetime.now().isoformat()
        })
        
        return empathetic_response
    
    def get_emotional_history(self) -> List[Dict]:
        """ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø§Ø­Ø³Ø§Ø³ÛŒ"""
        return list(self.emotional_memory)


class HumanizationEngine:
    """Ù…ÙˆØªÙˆØ± Ø§Ù†Ø³Ø§Ù†ÛŒâ€ŒØ³Ø§Ø²ÛŒ"""
    
    def __init__(self):
        self.personality_adapter = PersonalityAdapter()
        self.emotional_intelligence = EmotionalIntelligence()
        self.response_variations = self._load_variations()
        
    def _load_variations(self) -> Dict[str, List[str]]:
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªÙ†ÙˆØ¹ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§"""
        return {
            'greeting': [
                "Ø³Ù„Ø§Ù…!",
                "Ø¯Ø±ÙˆØ¯!",
                "Ù‡ÛŒ!",
                "Hello!",
                "Hi there!",
                "Ø³Ù„Ø§Ù… Ø¯ÙˆØ³Øª Ù…Ù†!"
            ],
            'acknowledgment': [
                "ÙÙ‡Ù…ÛŒØ¯Ù…",
                "Ø¨Ø§Ø´Ù‡",
                "Ù…ØªÙˆØ¬Ù‡ Ø´Ø¯Ù…",
                "Got it",
                "I see",
                "Ø¯Ø±Ø³ØªÙ‡"
            ],
            'thinking': [
                "Ø¨Ø°Ø§Ø± ÙÚ©Ø± Ú©Ù†Ù…...",
                "Ø®Ø¨...",
                "Ø¬Ø§Ù„Ø¨Ù‡...",
                "Hmm...",
                "Let me think...",
                "ÛŒÙ‡ Ù„Ø­Ø¸Ù‡..."
            ],
            'transition': [
                "Ø±Ø§Ø³ØªÛŒØŒ",
                "ÛŒÙ‡ Ú†ÛŒØ² Ø¯ÛŒÚ¯Ù‡ØŒ",
                "Ø¶Ù…Ù†Ø§Ù‹ØŒ",
                "By the way,",
                "Also,",
                "Ø¯Ø± Ø¶Ù…Ù†ØŒ"
            ]
        }
    
    async def humanize_response(self, user_id: str, message: str,
                               base_response: str) -> str:
        """Ø§Ù†Ø³Ø§Ù†ÛŒ Ú©Ø±Ø¯Ù† Ù¾Ø§Ø³Ø®"""
        
        # 1. ØªØ·Ø¨ÛŒÙ‚ Ø¨Ø§ Ø´Ø®ØµÛŒØª Ú©Ø§Ø±Ø¨Ø±
        adapted = await self.personality_adapter.adapt_response(
            user_id, message, base_response
        )
        
        # 2. Ø§ÙØ²ÙˆØ¯Ù† Ù‡ÙˆØ´ Ø§Ø­Ø³Ø§Ø³ÛŒ
        empathetic = await self.emotional_intelligence.generate_empathetic_response(
            message, adapted
        )
        
        # 3. Ø§ÙØ²ÙˆØ¯Ù† ØªÙ†ÙˆØ¹
        humanized = self._add_natural_variations(empathetic)
        
        # 4. Ø§ÙØ²ÙˆØ¯Ù† ØªØ§Ø®ÛŒØ± ØªØ§ÛŒÙ¾ (Ø¨Ø±Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒâ€ŒØªØ± Ø¨ÙˆØ¯Ù†)
        typing_delay = self._calculate_typing_delay(humanized)
        
        return {
            'response': humanized,
            'typing_delay': typing_delay,
            'metadata': {
                'user_profile': self.personality_adapter.get_or_create_profile(user_id).build_profile(),
                'emotion_detected': await self.emotional_intelligence.detect_emotion(message)
            }
        }
    
    def _add_natural_variations(self, response: str) -> str:
        """Ø§ÙØ²ÙˆØ¯Ù† ØªÙ†ÙˆØ¹ Ø·Ø¨ÛŒØ¹ÛŒ"""
        
        # Ú¯Ø§Ù‡ÛŒ Ø§ÙØ²ÙˆØ¯Ù† "thinking" Ø¯Ø± Ø§Ø¨ØªØ¯Ø§
        if np.random.random() < 0.2:
            thinking = np.random.choice(self.response_variations['thinking'])
            response = f"{thinking} {response}"
        
        # Ú¯Ø§Ù‡ÛŒ Ø§ÙØ²ÙˆØ¯Ù† acknowledgment
        if np.random.random() < 0.15:
            ack = np.random.choice(self.response_variations['acknowledgment'])
            response = f"{ack}. {response}"
        
        return response
    
    def _calculate_typing_delay(self, text: str) -> float:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØ§Ø®ÛŒØ± ØªØ§ÛŒÙ¾ ÙˆØ§Ù‚Ø¹ÛŒ"""
        # Ø´Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø±Ø¹Øª ØªØ§ÛŒÙ¾ Ø§Ù†Ø³Ø§Ù† (50-80 Ú©Ù„Ù…Ù‡ Ø¯Ø± Ø¯Ù‚ÛŒÙ‚Ù‡)
        words = len(text.split())
        wpm = np.random.uniform(50, 80)
        delay = (words / wpm) * 60
        
        # Ø§ÙØ²ÙˆØ¯Ù† ØªØ§Ø®ÛŒØ± ÙÚ©Ø± Ú©Ø±Ø¯Ù†
        thinking_delay = np.random.uniform(1, 3)
        
        return delay + thinking_delay
